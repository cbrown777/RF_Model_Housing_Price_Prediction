---
title: "SIPPA Autoregression Modeling Program - VERSION 2"
author: "Connor Brown"
date: "3/13/2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r}
#Clear Workspace
rm(list = ls())

getwd() #Check to see what the working directory is
setwd("~/Desktop") #Set the working directory to wherever the file is located

CR_df <- read.csv("FAKE_Testing_Data.csv", header=TRUE) #Read the file in. Make sure the file is saved as a csv, and is stored on the Desktop
View(CR_df) #Open a new window for the dataframe

colnames(CR_df) #Check the column names of the dataframe

#Check unique values for CR_df and # of those unique values
unique(CR_df$device_ID)
length(unique(CR_df$device_ID))
```



```{r}
#Creates List of Lists where the key of the list is participant_ID and the first element of the inner lists is a compliance ratio vector  

convert_DF_to_List_of_Vectors <- function(data_frame){

  #Splits main dataframe into separate df's based on participantID
  split_df <- split(data_frame, data_frame$device_ID)

  #Initialize List of lists
  my_list_of_lists <- list()

  #Create list that contains all of the participantID's as keys, and their associated compliance ratios as numeric vectors 
  for (i in seq(1, length(split_df))){
    
      my_list <- list(device_ID = as.character(unique(split_df[[i]]$device_ID)), cluster_NUM = as.character(unique(split_df[[i]]$cluster_num)), Self_Monitoring_CR = c(split_df[[i]]$sm_cr), diet_ER = c(split_df[[i]]$diet_er), exercise_ER = c(split_df[[i]]$exercise_er), other_ER = c(split_df[[i]]$other_er) ) 
      my_list_of_lists <- append(my_list_of_lists, list(my_list))
      names(my_list_of_lists)[i] <- paste0( toString(unique(split_df[[i]]$device_ID)) )
      
  }
  
  return(my_list_of_lists)

}

```




```{r}

#Create List of Lists with participant_ID as key 
List_of_Lists_with_Vectors <- convert_DF_to_List_of_Vectors(CR_df)
List_of_Lists_with_Vectors
```


```{r}
#Load dynlm package
pacman::p_load(dynlm)
```


```{r}

#BIC Selection Code Base

#Function to compute BIC for AR model objects of class 'dynlm'***
BIC <- function(model) {
  
  ssr <- sum(model$residuals^2)
  t <- length(model$residuals)
  npar <- length(model$coef)
  
  return(
    round(c("p" = npar - 1,
          "BIC" = log(ssr/t) + npar * log(t)/t,
          "R2" = summary(model)$r.squared), 4)
  )
}

```


```{r}

#Loop BIC over models of different orders
return_Lag_Order_of_Lowest_BIC <- function(time_series_object) {
  
  order <-  c(1 : (length(time_series_object) - 1))

  BICs <- sapply(order, function(x) 
    "AR" = BIC(dynlm(time_series_object ~ L(time_series_object, 1:x))))

  return(BICs)
  
  #Select the AR model with the smallest BIC
  # return( BICs[, which.min(BICs[2, ])] )

}

```


```{r}

#*****Need to write function that selects order from either AIC or BIC Table - Discuss with Bon*****
#For now, we will just go with the AIC order

Select_Order_From_AIC_or_BIC <- function(AIC_Lag_Order, BIC_Table){
  
  chosen_Order <- AIC_Lag_Order
  return(chosen_Order)

}

```




```{r}

#**Not sure yet if you need to load this 
pacman::p_load(gsubfn)


#Function to compute the n = 1 predicted value, and compare to actual value to create forecast error
return_Best_Method <- function(TS_Vector){
  
  method_Vec <- c("yule-walker", "burg", "ols", "mle")
  
  method_Name_Vec <- c()
  forecast_Error_Vec <- c()
  
  for (chosen_Method in method_Vec) {
    
    #Stores most recent data point for data validation
    test_Data_Point <- TS_Vector[ length(TS_Vector) ]
    
    #Builds Autoregressive model using all EXCEPT the most recent data point
    test_TS_Model <- ar( x = as.ts( TS_Vector[ -length(TS_Vector) ] ), method = chosen_Method)
    
    #Returns the predicted value for the next week's deltaCR
    predicted_Value <- predict(test_TS_Model, n.ahead = 1)$pred[1]
    
    #Actual value minus predicted value
    forecast_Error <- test_Data_Point - predicted_Value
    
    method_Name_Vec <- c(method_Name_Vec, chosen_Method)
    forecast_Error_Vec <- c(forecast_Error_Vec, forecast_Error)
    
  }
  
  forecast_Error_Vec <- abs(forecast_Error_Vec)
  names(forecast_Error_Vec) <- method_Name_Vec
  names( which ( forecast_Error_Vec == min( abs(forecast_Error_Vec) ) ) )[1]
  
}


```



```{r}

generate_Final_Predicted_Value <- function(vector_For_Model, AR_method){
  
  #Build AR model with ALL Data and using the chosen method, as well as chosen lag order
  AR_Model_With_ALL_Data <- ar( x = as.ts(vector_For_Model), method = AR_method)
  
  #Returns the predicted value for the next week
  predicted_Value <- predict(AR_Model_With_ALL_Data, n.ahead = 1)$pred[1]
  
}

```



```{r}

#Function to create Time Series Objects from CR numeric vectors, and then determine the lag order
get_Predicted_Value <- function(vector_For_Model){

      #Makes ts object with delta values
      Ts_Vec <- diff( as.ts(vector_For_Model) , differences = 1)
      AIC_Lag_Order <- ar.ols(Ts_Vec)$order
      BIC_Table <- return_Lag_Order_of_Lowest_BIC(Ts_Vec)
      Chosen_Order <- Select_Order_From_AIC_or_BIC(AIC_Lag_Order, BIC_Table)
      
      #Call return_Best_Method to build 4 AR models (yule-walker, burg, ols, mle), and return the name of the method (as a character vector) that we'll use to build the final model with ALL of the data
      #Used to be:     best_AR_Method <- return_Best_Method(Ts_Vec, Chosen_Order) #Chosen_Order was taken out due to issues with fitting models
      best_AR_Method <- return_Best_Method(Ts_Vec)
      
      #Pass in the Time Series Vector with the best AR method and return the n+1 predicted value
      #Used to be:    final_Predicted_Value <- generate_Final_Predicted_Value(Ts_Vec, Chosen_Order, best_AR_Method)
      final_Predicted_Value <- generate_Final_Predicted_Value(Ts_Vec, best_AR_Method)
      
}

```







```{r}

#Function to generate a list of lists containing empty vecs and arrays to be used to generate joint PMF's
generate_empty_List_Of_Vecs_And_Arrays <- function(vec_of_clusters){

  #Initialize List of lists
  my_list_of_lists <- list()

  for (i in vec_of_clusters ){
    
      generic_vec_and_array_list <- list(predicted_delta_CR_vec = vector("numeric", 0), recent_CR_vec = vector("numeric", 0), predicted_delta_diet_ER_vec = vector("numeric", 0), recent_diet_ER_vec = vector("numeric", 0), predicted_delta_exercise_ER_vec = vector("numeric", 0), recent_exercise_ER_vec = vector("numeric", 0), predicted_delta_other_ER_vec = vector("numeric", 0), recent_other_ER_vec = vector("numeric", 0), CR_Matrix = matrix(NA,3,3), diet_ER_Matrix = matrix(NA,3,3), exercise_ER_Matrix = matrix(NA,3,3), other_ER_Matrix = matrix(NA,3,3))
      my_list_of_lists <- append(my_list_of_lists, list(generic_vec_and_array_list))
      names(my_list_of_lists)[i] <- paste0("Cluster", toString( i ) )
      
  }
  
  return(my_list_of_lists)

}

```




```{r}
#generate_Joint_PMFs VERSION 2

generate_Joint_PMFs <- function(List_of_Lists){

  #Pull unique values for clusters and plug in to generate empty list of vecs and arrays for Joint PMF
  #Length of List determined by number of unique clusters in **DATAFRAME**
  #Not a very good operation, but it will do for now
  List_Of_Vecs_And_Arrays <- generate_empty_List_Of_Vecs_And_Arrays( sort(unique(CR_df$cluster_num)) )
  
  for(i in seq(1, length(List_of_Lists)) ){
    
    #Pulls cluster number from device_ID List Object and converts from character to numeric 
    cluster_num <- as.numeric( List_of_Lists[[i]]$cluster_NUM )
    
    #Creates NEW list containing ONLY the vectors (NO device_ID OR Cluster #)
    new_List <- List_of_Lists[[i]][-c(1,2)]
    
    h = 0
    
    for(j in seq(1, length(new_List)) ){

      #Store the most recent value for that vector
      most_recent_value <- new_List[[j]][ length(new_List[[j]]) ]
    
      cat("i is", i,"cluster_num is", cluster_num, "j is", j, "most_recent_value is ", most_recent_value, "\n")
      
      #Store the predicted delta value for that vector
      predicted_value <- get_Predicted_Value( new_List[[j]] )
      
      #Adds predicted values and most recent values to the associated vectors
      List_Of_Vecs_And_Arrays[[cluster_num]][[ j + h ]] <-  c( List_Of_Vecs_And_Arrays[[cluster_num]][[ j + h ]] , predicted_value )
      List_Of_Vecs_And_Arrays[[cluster_num]][[ j + (h+1) ]] <- c( List_Of_Vecs_And_Arrays[[cluster_num]][[ j + (h+1) ]] , most_recent_value )
      
      h = h + 1
      
    }
    
  }
  
  return(List_Of_Vecs_And_Arrays)

}

```






```{r}

#TEST
TEST <- generate_Joint_PMFs(List_of_Lists_with_Vectors)


TEST













```



```{r}

#TESTING AREA







```



```{r}






```



```{r}


#Used to determine percentile values for a vector 
first_third_percentile_value <- qnorm(0.333, mean = mean(test_vec), sd = sd(test_vec) )
second_third_percentile_value <- qnorm(0.666, mean = mean(test_vec), sd = sd(test_vec) )




```







```{r}
# #generate_Joint_PMFs VERSION 1
# 
# generate_Joint_PMFs <- function(List_of_Lists){
# 
#   #Get NAMES of vectors as a character vector from the FIRST LIST ELEMENT and removes the first 2 elements
#   #Not a very good operation, but it will do for now
#   vector_names_vec <- names(List_of_Lists[[1]])[-c(1:2)]
# 
#   #Pull unique values for clusters and plug in to generate empty list of vecs and arrays for Joint PMF
#   #Length of List determined by number of unique clusters in **DATAFRAME**
#   #Not a very good operation, but it will do for now
#   List_Of_Vecs_And_Arrays <- generate_empty_List_Of_Vecs_And_Arrays( sort(unique(CR_df$cluster_num)) )
# 
#   for(i in seq(1, length(List_of_Lists)) ){
# 
#     #Pulls cluster number from device_ID List Object and converts from character to numeric
#     cluster_num <- as.numeric( List_of_Lists[[i]]$cluster_NUM )
# 
#     for(vector_name in vector_names_vec){
# 
#       #Store the most recent value for that vector
#       most_recent_value <- List_of_Lists[[i]]$vector_name[ length(List_of_Lists[[i]]$vector_name) ]
# 
# 
#       cat("i is", i,"cluster_num is", cluster_num, "vector_name is", vector_name, "most_recent_value is ", most_recent_value, "\n")
# 
# 
#       #Store the predicted delta value for that vector
#       predicted_value <- get_Predicted_Value( List_of_Lists[[i]]$vector_name )
# 
#       if(vector_name == "Self_Monitoring_CR"){
#         append( List_Of_Vecs_And_Arrays[[cluster_num]]$recent_CR_vec , most_recent_value)
#         append( List_Of_Vecs_And_Arrays[[cluster_num]]$predicted_delta_CR_vec , predicted_value)
#       }
# 
#       if(vector_name == "diet_ER"){
#         append( List_Of_Vecs_And_Arrays[[cluster_num]]$recent_diet_ER_vec , most_recent_value)
#         append( List_Of_Vecs_And_Arrays[[cluster_num]]$predicted_delta_diet_ER_vec , predicted_value)
#       }
# 
#       if(vector_name == "exercise_ER"){
#         append( List_Of_Vecs_And_Arrays[[cluster_num]]$recent_exercise_ER_vec , most_recent_value)
#         append( List_Of_Vecs_And_Arrays[[cluster_num]]$predicted_delta_exercise_ER_vec , predicted_value)
#       }
# 
#       if(vector_name == "other_ER"){
#         append( List_Of_Vecs_And_Arrays[[cluster_num]]$recent_other_ER_vec , most_recent_value)
#         append( List_Of_Vecs_And_Arrays[[cluster_num]]$predicted_delta_other_ER_vec , predicted_value)
#       }
# 
#     }
# 
#   }
# 
#   return(List_Of_Vecs_And_Arrays)
# 
# }

```


















```{r}

#Initial Setup

#Clear Workspace
rm(list = ls())

#Needed for remove_empty function
pacman::p_load("janitor")

getwd() #Check to see what the working directory is
setwd("~/Desktop") #Set the working directory to wherever the file is located

```



```{r}

#Data Processing Program for Compliance Ratio Data 


#Reads self-monitoring file in
txt_2_CR_df <- read.delim("ccd_logs-15.txt", header = FALSE, na.strings=c("", "NA"))
#Removes all columns with ALL NA's
txt_2_CR_df <- remove_empty(txt_2_CR_df, which = "cols")
#Set first column name as "device_ID"
colnames(txt_2_CR_df)[1] <- c("device_ID")
colnames(txt_2_CR_df) #Check the column names of the dataframe

#View the dataframe
View(txt_2_CR_df)

#Convert entries of dataframe from factors to Dates
txt_2_CR_df[,-1] <- lapply(txt_2_CR_df[,-1], function(x) as.Date(x))

#Test to make sure new class is Date
class(txt_2_CR_df$V2[5])


#Load lubridate library for dealing with dates and times 
pacman::p_load(lubridate)


# 
# 
# #Convert any dates from before 2019 to NA's throughout the dataframe
# 
# #Work on this function - it's being a pain in the ass
# 
# 
# column_Name_Vec <- colnames(txt_2_CR_df[ ,-1])
# column_Name_Vec
# 
# for(column_Name in column_Name_Vec){
# 
#   txt_2_CR_df$column_Name[year(txt_2_CR_df$column_Name) < 2019] <- NA
# 
# }




#Identify the earliest date in the dataframe
earliest_date <- as.Date( min( apply(txt_2_CR_df[,-1], 2, min, na.rm = TRUE) ) )

#Identify the first Sunday in the dataframe
first_Sunday <- floor_date( earliest_date, unit="week" )

#Replaces dates with integers representing Week #
txt_2_CR_df[,-1] <- lapply(txt_2_CR_df[,-1], function(x) as.integer( floor(difftime(x, first_Sunday, units = "weeks")))      )

```



# What if I want to use one of the masked functions?
# 
# You can explicitly provide a package name when you call a function, using the double colon operator, ::

#https://stackoverflow.com/questions/39137110/what-does-the-following-object-is-masked-from-packagexxx-mean



```{r}

pacman::p_load(plyr)

#Attaching package: ‘plyr’

# The following object is masked from ‘package:lubridate’:
# 
#     here

#Splits main dataframe into list of df's based on device_ID
split_CR_DF <- dlply(txt_2_CR_df, .(device_ID) )


#Vectorize df excluding device_ID column 
test <- unlist( split_CR_DF[[6]][ , -1] , use.names = FALSE)


test

table(test)


                   
                   
                   
table(split_CR_DF[[5]])



?aggregate

aggregate(data.frame(count = v), list(value = v), length)








dummyData = rep(c(1,2, 2, 2), 25)
class(dummyData)

table(dummyData)

test <- as.data.frame(table(dummyData))

test


```





```{r}

#Data Processing Program for Engagement Ratio Data 


#Reads engagement ratio file in
Engagement_Ratio_df <- read.csv("Engagement_Ratio_Data.csv", header = TRUE) 
#Removes all rows that don't contain daily wisdom notifications
Engagement_Ratio_df <- Engagement_Ratio_df[ Engagement_Ratio_df$title == "Daily Wisdom", ]
#Removes all columns with ALL NA's
Engagement_Ratio_df <- remove_empty(Engagement_Ratio_df, which = "cols")

View(Engagement_Ratio_df)
class(Engagement_Ratio_df)
nrow(Engagement_Ratio_df)
ncol(Engagement_Ratio_df)






colnames(CR_df) <- c("participant_ID", "compliance_Ratio")
colnames(CR_df) #Check the column names of the dataframe

#Check unique values for CR_df and # of those unique values
unique(CR_df$participant_ID)
length(unique(CR_df$participant_ID))

```
















